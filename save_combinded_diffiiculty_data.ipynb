{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2lNtygyYivyIwu550ZUhv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BorisLoveDev/agents-of-uniform-difficulty/blob/main/save_combinded_diffiiculty_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3d1NB3H9NYBM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import os\n",
        "import random\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Подключение Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG3k8YtrNtRc",
        "outputId": "9366607e-40a2-446d-ead0-b03d309b08ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и нормализация данных MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# Добавление измерения канала к данным\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Применение one-hot encoding\n",
        "y_test_ohe = to_categorical(y_test, num_classes)\n",
        "y_train_ohe = to_categorical(y_train, num_classes)\n",
        "y_train_ohe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vL8MyvHOzw3",
        "outputId": "bec6df1a-3d6c-4266-edca-b63fc12380c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных для уровня сложности 0\n",
        "x_data_level_0 = np.load('/content/drive/MyDrive/all_difficulty_data_mnist/x_data_difficult_level_0.npy')\n",
        "y_data_level_0 = np.load('/content/drive/MyDrive/all_difficulty_data_mnist/y_data_difficult_level_0.npy')\n",
        "\n",
        "# Загрузка данных для уровня сложности 6\n",
        "x_data_level_6 = np.load('/content/drive/MyDrive/all_difficulty_data_mnist/x_data_difficult_level_6.npy')\n",
        "y_data_level_6 = np.load('/content/drive/MyDrive/all_difficulty_data_mnist/y_data_difficult_level_6.npy')\n"
      ],
      "metadata": {
        "id": "BvIVVQ-xPltK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для деформации изображения, как определено ранее\n",
        "def deform_image_optimized(image, A, B, M=28, NP=5):\n",
        "    C = M / (NP + 1.0)\n",
        "    XN, YN = np.zeros(M), np.zeros(M)\n",
        "    DX, DY = np.linspace(0, M-1, M), np.linspace(0, M-1, M)\n",
        "\n",
        "    for j in range(NP):\n",
        "        TXN = (j + 0.5 - np.random.random()) * C\n",
        "        TYN = (j + 0.5 - np.random.random()) * C\n",
        "        TDX = (j + 0.5 - np.random.random()) * C\n",
        "        TDY = (j + 0.5 - np.random.random()) * C\n",
        "        AXN = B * (1.0 - 2.0 * np.random.random())\n",
        "        AYN = B * (1.0 - 2.0 * np.random.random())\n",
        "        ADX = A * (1.0 - 2.0 * np.random.random())\n",
        "        ADY = A * (1.0 - 2.0 * np.random.random())\n",
        "        PXN = (0.1 + 0.9 * np.random.random()) * C\n",
        "        PYN = (0.1 + 0.9 * np.random.random()) * C\n",
        "        PDX = (0.1 + 0.9 * np.random.random()) * C\n",
        "        PDY = (0.1 + 0.9 * np.random.random()) * C\n",
        "\n",
        "        DX += ADX * np.exp(-((DX - TDX) / PDX)**2)\n",
        "        DY += ADY * np.exp(-((DY - TDY) / PDY)**2)\n",
        "        XN += AXN * np.exp(-((DX - TXN) / PXN)**2)\n",
        "        YN += AYN * np.exp(-((DY - TYN) / PYN)**2)\n",
        "\n",
        "    deformed_image = np.zeros((M, M))\n",
        "    for j in range(M):\n",
        "        for i in range(M):\n",
        "            x_index = int(DX[i] + XN[j])\n",
        "            y_index = int(DY[j] + YN[i])\n",
        "            if 0 <= x_index < M and 0 <= y_index < M:\n",
        "                deformed_image[j, i] = image[y_index, x_index] if y_index < image.shape[0] and x_index < image.shape[1] else 0\n",
        "\n",
        "    return deformed_image"
      ],
      "metadata": {
        "id": "rFHog_wUPQeM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deform_params = {\n",
        "    \"1\": (0.2, 1.0),\n",
        "    \"2\": (0.4, 3.0),\n",
        "    \"3\": (1, 5.0),\n",
        "    \"4\": (3.5, 9.5),\n",
        "    \"5\": (5, 15.0),\n",
        "}"
      ],
      "metadata": {
        "id": "jq_c5mlAPSkd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Взятие по 1500 изображений из уровней сложности 0 и 6\n",
        "x_data_level_0_subset = x_data_level_0[:1500]\n",
        "y_data_level_0_subset = y_data_level_0[:1500]\n",
        "x_data_level_6_subset = x_data_level_6[:1500]\n",
        "y_data_level_6_subset = y_data_level_6[:1500]\n",
        "\n",
        "# Убедимся, что все массивы имеют одинаковое количество измерений\n",
        "x_data_level_0_subset = np.expand_dims(x_data_level_0_subset, axis=-1) if x_data_level_0_subset.ndim == 3 else x_data_level_0_subset\n",
        "x_data_level_6_subset = np.expand_dims(x_data_level_6_subset, axis=-1) if x_data_level_6_subset.ndim == 3 else x_data_level_6_subset\n",
        "\n",
        "# Инициализация списка для объединения с проверкой размерности\n",
        "x_combined = [x_data_level_0_subset]\n",
        "y_combined = [y_data_level_0_subset]\n",
        "\n",
        "# Генерация деформированных изображений для уровней сложности с 1 по 5 и добавление их в список\n",
        "for level, params in deform_params.items():\n",
        "    A, B = params\n",
        "    start_index = 1500 * int(level)  # Исправленный начальный индекс для x_test\n",
        "    end_index = start_index + 1500\n",
        "    x_subset = x_test[start_index:end_index]\n",
        "    y_subset = y_test[start_index:end_index]\n",
        "\n",
        "    # Деформация изображений\n",
        "    x_deformed = np.array([deform_image_optimized(img.squeeze(), A, B) for img in x_subset])\n",
        "    x_deformed = np.expand_dims(x_deformed, axis=-1)  # Проверка не требуется, всегда добавляем измерение канала\n",
        "\n",
        "    x_combined.append(x_deformed)\n",
        "    y_combined.append(y_subset)\n",
        "\n",
        "# Добавление изображений уровня сложности 6 в конец\n",
        "x_combined.append(x_data_level_6_subset)\n",
        "y_combined.append(y_data_level_6_subset)\n",
        "\n",
        "# Преобразование списков в массивы Numpy и их объединение\n",
        "x_combined = np.concatenate(x_combined, axis=0)\n",
        "y_combined = np.concatenate(y_combined, axis=0)\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "#y_combined_ohe = to_categorical(y_combined, num_classes)\n",
        "\n",
        "print(f\"Форма итогового набора данных: {x_combined.shape}\")\n",
        "print(f\"Форма итоговых меток: {y_combined.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lus6o8BmPmsY",
        "outputId": "7314127f-647c-41d9-890a-2bda395ef170"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма итогового набора данных: (10500, 28, 28, 1)\n",
            "Форма итоговых меток: (10500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к директории на Google Drive\n",
        "save_dir = '/content/drive/MyDrive/all_difficulty_data_mnist'\n",
        "\n",
        "# Создание директории, если она еще не существует\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Пути для сохранения файлов\n",
        "x_save_path = os.path.join(save_dir, 'x_combined_difficulty.npy')\n",
        "y_save_path = os.path.join(save_dir, 'y_combined_difficulty.npy')\n",
        "#y_ohe_save_path = os.path.join(save_dir, 'y_combined_difficulty_ohe.npy')\n",
        "\n",
        "# Сохранение наборов данных\n",
        "np.save(x_save_path, x_combined)\n",
        "np.save(y_save_path, y_combined)\n",
        "#np.save(y_ohe_save_path, y_combined_ohe)\n",
        "\n",
        "print(f'Наборы данных сохранены в {save_dir}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_p4O6wOTTQl",
        "outputId": "a0110dd4-c145-4cdd-fe1f-d179f6975e81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наборы данных сохранены в /content/drive/MyDrive/all_difficulty_data_mnist\n"
          ]
        }
      ]
    }
  ]
}